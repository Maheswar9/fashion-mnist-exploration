{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    \n",
    "import pandas as pd\n",
    "import gzip\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def showImage(data):\n",
    "    some_article = data   # Selecting the image.\n",
    "    some_article_image = some_article.reshape(28, 28) # Reshaping it to get the 28x28 pixels\n",
    "    plt.imshow(some_article_image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "filePath_train_set = '../data/train-images-idx3-ubyte.gz'\n",
    "filePath_train_label = '../data/train-labels-idx1-ubyte.gz'\n",
    "\n",
    "filePath_test_set = '../data/t10k-images-idx3-ubyte.gz'\n",
    "filePath_test_label = '../data/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "with gzip.open(filePath_train_label, 'rb') as trainLbpath:\n",
    "     trainLabel = np.frombuffer(trainLbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "with gzip.open(filePath_train_set, 'rb') as trainSetpath:\n",
    "     trainSet = np.frombuffer(trainSetpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(trainLabel), 784)\n",
    "\n",
    "with gzip.open(filePath_test_label, 'rb') as testLbpath:\n",
    "     testLabel = np.frombuffer(testLbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "with gzip.open(filePath_test_set, 'rb') as testSetpath:\n",
    "     testSet = np.frombuffer(testSetpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(testLabel), 784)\n",
    "\n",
    "print(type(testLabel))\n",
    "\n",
    "print(trainSet.shape)\n",
    "\n",
    "print(trainLabel.shape)\n",
    "\n",
    "print(testSet.shape)\n",
    "\n",
    "print(testLabel.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = trainSet, testSet, trainLabel, testLabel\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "showImage(X_train[0])\n",
    "y_train[0]\n",
    "# Shuffling\n",
    "np.random.seed(42)   # if you want reproducible results set the random seed value.\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "#  import  libraries \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# using Softmax Regression (multi-class classification problem)\n",
    "log_clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10, random_state=42,max_iter=5000)\n",
    "# 'C' is hyprparameter for regularizing L2\n",
    "# 'lbfgs' is Byoden-Fletcher-Goldfarb-Shanno(BFGS) algorithm\n",
    "log_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "#predict some instance from the dataset using the above trained model\n",
    "y_train_predict = log_clf.predict(X_train[0].reshape(1, -1))\n",
    "\n",
    "y_train[0]\n",
    "\n",
    "\n",
    "\n",
    "y_train_predict[0]\n",
    "\n",
    "showImage(X_train[0])\n",
    "\n",
    "#  predict all instances of training dataset X_train_scaled using the above trained model\n",
    "y_train_predict = log_clf.predict(X_train_scaled)\n",
    "\n",
    "log_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "log_precision = precision_score(y_train, y_train_predict, average='weighted')\n",
    "log_recall = recall_score(y_train, y_train_predict, average='weighted')\n",
    "log_f1_score = f1_score(y_train, y_train_predict, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Logistic Accuracy: \", log_accuracy)\n",
    "print(\"Logistic Precision: \", log_precision)\n",
    "print(\"Logistic Recall: \", log_recall)\n",
    "print(\"Logistic F1 Score: \", log_f1_score)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=20, max_depth=10, random_state=42)\n",
    "\n",
    "# Scaling is not needed for Decision Tree algorithm and hence for Random Forest and XGBoost algorithms as they \n",
    "# are also based on Decision Trees. Hence, not using scaled training dataset here\n",
    "\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "#  predict some instance from the data set using the above trained model\n",
    "y_train_predict = rnd_clf.predict(X_train[0].reshape(1, -1))\n",
    "\n",
    "y_train[0]\n",
    "\n",
    "y_train_predict[0]\n",
    "\n",
    "showImage(X_train[0])\n",
    "\n",
    "#  predict all instances of training dataset X_train using the above trained model\n",
    "y_train_predict = rnd_clf.predict(X_train)\n",
    "\n",
    "rnd_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "rnd_precision = precision_score(y_train, y_train_predict, average='weighted')\n",
    "rnd_recall = recall_score(y_train, y_train_predict, average='weighted')\n",
    "rnd_f1_score = f1_score(y_train, y_train_predict, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Random Forest Accuracy: \", rnd_accuracy)\n",
    "print(\"Random Forest Precision: \", rnd_precision)\n",
    "print(\"Random Forest Recall: \", rnd_recall)\n",
    "print(\"Random Forest F1 Score: \", rnd_f1_score)\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# function to calculate mean and standard deviation of each score (e.g. accuracy, precision, etc.)\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "log_clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10, random_state=42,\n",
    "max_iter=5000) \n",
    "\n",
    "log_cv_scores = cross_val_score(log_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\") \n",
    "display_scores(log_cv_scores)\n",
    "log_cv_accuracy = log_cv_scores.mean()\n",
    "\n",
    "y_train_pred = cross_val_predict(log_clf, X_train_scaled, y_train, cv=3)\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "log_cv_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "log_cv_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "log_cv_f1_score = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "print(\"Logistic CV Accuracy: \", log_cv_accuracy)\n",
    "print(\"Logistic CV Precision: \", log_cv_precision)\n",
    "print(\"Logistic CV Recall: \", log_cv_recall)\n",
    "print(\"Logistic CV F1 Score: \", log_cv_f1_score)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=20, max_depth=10, random_state=42)\n",
    "\n",
    "rnd_cv_scores = cross_val_score(rnd_clf, X_train, y_train, cv=3, scoring=\"accuracy\") \n",
    "display_scores(rnd_cv_scores)\n",
    "rnd_cv_accuracy = rnd_cv_scores.mean()\n",
    "\n",
    "y_train_pred = cross_val_predict(rnd_clf, X_train, y_train, cv=3)\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "rnd_cv_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "rnd_cv_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "rnd_cv_f1_score = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "print(\"Random Forest CV Accuracy: \", rnd_cv_accuracy)\n",
    "print(\"Random Forest CV Precision: \", rnd_cv_precision)\n",
    "print(\"Random Forest CV Recall: \", rnd_cv_recall)\n",
    "print(\"Random Forest CV F1 Score: \", rnd_cv_f1_score)\n",
    "print(\"=== Softmax === \")\n",
    "display_scores(log_cv_scores)\n",
    "print(\"log_cv_accuracy:\", log_cv_accuracy)\n",
    "print(\"log_cv_precision:\", log_cv_precision)\n",
    "print(\"log_cv_recall:\", log_cv_recall)\n",
    "print(\"log_cv_f1_score:\", log_cv_f1_score)\n",
    "\n",
    "print(\"=== Random Forest === \")\n",
    "display_scores(rnd_cv_scores)\n",
    "print(\"rnd_cv_accuracy:\", rnd_cv_accuracy)\n",
    "print(\"rnd_cv_precision:\", rnd_cv_precision)\n",
    "print(\"rnd_cv_recall :\", rnd_cv_recall )\n",
    "print(\"rnd_cv_f1_score:\", rnd_cv_f1_score)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "pca.n_components_\n",
    "\n",
    "# Checking if hit your 99% minimum?\n",
    "np.sum(pca.explained_variance_ratio_)\n",
    "\n",
    "# use inverse_transform to decompress back to 784 dimensions\n",
    "\n",
    "X_train_recovered = pca.inverse_transform(X_train_reduced)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digits(instances, images_per_row=5, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, **options)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.subplot(121)\n",
    "# Plotting 'original' image\n",
    "plot_digits(X_train[::2100])\n",
    "plt.title(\"Original\", fontsize=16)\n",
    "plt.subplot(122)\n",
    "# Plotting the corresponding 'recovered' image\n",
    "plot_digits(X_train_recovered[::2100])\n",
    "plt.title(\"Compressed\", fontsize=16)\n",
    "plt.show()\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "log_clf_ens = LogisticRegression(multi_class=\"multinomial\", solver=\"lbgfs\", C=10 , random_state=42, max_iter=5000)\n",
    "rnd_clf_ens = RandomForestClassifier(n_estimators=20, max_depth=10 , random_state=42)\n",
    "\n",
    "\n",
    "voting_clf_grid_search = VotingClassifier(\n",
    "    estimators=[('lr', log_clf_ens), ('rf', rnd_clf_ens)],\n",
    "    voting='soft')\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"lr__multi_class\":[\"multinomial\"],\n",
    "        \"lr__solver\":[\"saga\"],\n",
    "        \"lr__C\":[5],\n",
    "        \"rf__n_estimators\":[20],\n",
    "        \"rf__max_depth\":[10, 15],\n",
    "    }]\n",
    "\n",
    "grid_search = GridSearchCV(voting_clf_grid_search, param_grid, cv=3, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "grid_search.best_params_\n",
    "grid_search.best_estimator_\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "# Evaluate model on the test Set\n",
    "\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Remember, you have to use pca object of training dataset (you got on training dataset during dimensionality reduction)\n",
    "# and only apply transform on test dataset (not fit_transform) - highly important\n",
    "\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "y_test_predict = final_model.predict(X_test_reduced)\n",
    "\n",
    "confusion_matrix(y_test, y_test_predict)\n",
    "final_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "final_precision = precision_score(y_test, y_test_predict, average='weighted')\n",
    "final_recall = recall_score(y_test, y_test_predict, average='weighted')\n",
    "final_f1_score = f1_score(y_test, y_test_predict, average='weighted')\n",
    "\n",
    "\n",
    "print(\"Final Accuracy: \", final_accuracy)\n",
    "print(\"Final Precision: \", final_precision)\n",
    "print(\"Final Recall: \", final_recall)\n",
    "print(\"Final F1 Score: \", final_f1_score)\n",
    "\n",
    "# Just check with a sample value, if the predictions were correct\n",
    "\n",
    "y_test[0]\n",
    "\n",
    "y_test_predict[0]\n",
    "\n",
    "showImage(X_test[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
